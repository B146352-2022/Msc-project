{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf172459-6fac-4dac-9dd5-4efb1cd70f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 19:03:04.379500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten,Dropout,Conv2D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Reshape\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5103ccb1-d4cd-43e3-a9b8-0d38c2944110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the raw sequence\n",
    "def input_file(file_path):\n",
    "    \"\"\"\n",
    "    input is the path of fasta file\n",
    "    output is a list of sequences\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    current_sequence = \"\"\n",
    "\n",
    "    with open(fasta_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if current_sequence:\n",
    "                    sequences.append(current_sequence)\n",
    "                    current_sequence = \"\"\n",
    "            else:\n",
    "                current_sequence += line\n",
    "\n",
    "    if  current_sequence:\n",
    "        sequences.append(current_sequence)\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a99ece-a969-4301-bbc1-ccc23412fb99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one hot encoding for the input\n",
    "def one_hot_encode(seq):\n",
    "    \"\"\"\n",
    "    input is the individual sequence\n",
    "    output is the individual one-hot-encoded sequence\n",
    "    \"\"\"\n",
    "    map = np.asarray([[1,0,0,0,0],\n",
    "                      [0,1,0,0,0],\n",
    "                      [0,0,1,0,0],\n",
    "                      [0,0,0,1,0],\n",
    "                      [0,0,0,0,1]])\n",
    "    # replace ATCG with corresponding numbers\n",
    "    seq = seq.upper().replace('A','\\x00').replace('C','\\x01').replace('G', '\\x02').replace('T', '\\x03').replace('N','\\x04')\n",
    "    seq_array = np.fromstring(seq, np.int8)\n",
    "    seq_array = seq_array % 5\n",
    "    encoded_seq = map[seq_array]\n",
    "    \n",
    "    return encoded_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29368896-2cca-4719-8fee-08f75731d3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pad the sequence and get the input\n",
    "def process_input(sequences,chunk_size):\n",
    "    \"\"\"\n",
    "    To ensure every sequence has the same length, I pad the sequence with \"N\" up to the length of set chunk_size\n",
    "    Then encode every sequence to get the final input for the model\n",
    "    input: a list of raw sequences and chunk size\n",
    "    output: the input of model (X)\n",
    "    \"\"\"\n",
    "    padded_seq = []\n",
    "    pad = ''\n",
    "    for seq in sequences:\n",
    "        pad = seq.ljust(chunk_size, 'N')\n",
    "        padded_seq.append(pad)\n",
    "\n",
    "    one_hot_sequences = [one_hot_encode(seq) for seq in padded_seq]\n",
    "    seq_array = np.array(one_hot_sequences)\n",
    "    one_hot_length = 5\n",
    "    X = seq_array.reshape(-1, chunk_size, one_hot_length)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b020aa2d-ae03-4bcb-b3c5-6e3e540a6e69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# translate sequence to VDJ sequence\n",
    "def translate_output(df,idx):\n",
    "    \"\"\"\n",
    "    input: the path of annotation file and the index of each item (sequence)\n",
    "    output: the individual VDJ sequence like \"VVVVVDDDJJJ\"\n",
    "    \"\"\"\n",
    "    # store the start, end position and length of VDJ\n",
    "    # the start and end\n",
    "    positions = {\n",
    "    'V': [df.loc[idx, 'v_sequence_start'] - 1, df.loc[idx, 'v_sequence_end']-1],\n",
    "    'D': [df.loc[idx, 'd_sequence_start'] - 1, df.loc[idx, 'd_sequence_end']-1],\n",
    "    'J': [df.loc[idx, 'j_sequence_start'] - 1, df.loc[idx, 'j_sequence_end']-1],\n",
    "    }\n",
    "    # the length \n",
    "    for key in positions.keys():\n",
    "        positions[key].append(positions[key][1] - positions[key][0]+1)\n",
    "    \n",
    "    # create sequence\n",
    "    seq = ['X'] * (positions['J'][1] + 1)\n",
    "    \n",
    "    # replace the X with VDJN \n",
    "    for key, (start, end, length) in positions.items():\n",
    "        seq[start:end+1] = [key] * length\n",
    "    my_seq = ''.join(seq)\n",
    "    my_seq = my_seq.replace('X', 'N')\n",
    "    my_seq = my_seq.ljust(chunk_size, 'X')\n",
    "    \n",
    "    return my_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b52e69-070b-4b34-960b-45df149b3b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one-hot-encoding for the output\n",
    "def output_encoding(seq):\n",
    "    \"\"\"\n",
    "    input: the individual VDJ sequence\n",
    "    output: the individual encoded sequence\n",
    "    \"\"\"\n",
    "    map = np.asarray([[1,0,0,0,0],\n",
    "                      [0,1,0,0,0],\n",
    "                      [0,0,1,0,0],\n",
    "                      [0,0,0,1,0],\n",
    "                      [0,0,0,0,1]])\n",
    "   # replace VDJN with corresponding numbers\n",
    "    seq = seq.upper().replace('V','\\x00').replace('D','\\x01').replace('J', '\\x02').replace('N', '\\x03').replace('X','\\x04')\n",
    "    seq_array = np.fromstring(seq, np.int8)\n",
    "    seq_array = seq_array % 5\n",
    "    encoded_seq = map[seq_array]\n",
    "    \n",
    "    return encoded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c3b1346-4bf5-4cc5-8cf8-f594ea6cf4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the output\n",
    "def process_output(df):\n",
    "    \"\"\"\n",
    "    input: the dataframe obtained from the annotation file\n",
    "    output: the one-hot-encoded target label of the model\n",
    "    \"\"\"\n",
    "    encoded_VDJ = []\n",
    "    num_VDJ = []\n",
    "    for i in range(len(df)):\n",
    "        seq = translate_output(df,i)\n",
    "        seq_num = output_catogory(seq)\n",
    "        \n",
    "        num_VDJ.append(seq_num)\n",
    "        encoded_seq = output_encoding(seq)\n",
    "        encoded_VDJ.append(encoded_seq)\n",
    "        \n",
    "    y = np.array(encoded_VDJ)\n",
    "    y_class = np.array(num_VDJ)\n",
    "    \n",
    "    return y, y_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09514181-9f89-4a4f-b671-9e4a847b6807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# translate the VDJ sequence to 1,2,3,4 for performance evaluation\n",
    "def output_catogory(seq):\n",
    "    \"\"\"\n",
    "    input is the individual VDJ sequence\n",
    "    output is a list of numbers including 0,1,2,3,4, which respectively correspond to VDJNX\n",
    "    \"\"\"\n",
    "    seq = seq.replace('V','\\x00').replace('D','\\x01').replace('J', '\\x02').replace('N', '\\x03').replace('X','\\x04')\n",
    "    return np.fromstring(seq, np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8517c057-04b6-4a1d-8e8a-940d840af8e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_Xy(fasta_file, annotation_file):\n",
    "    sequences = input_file(fasta_file)\n",
    "    X = process_input(sequences, chunk_size)\n",
    "    df = pd.read_csv(annotation_file, sep='\\t', header=0)\n",
    "    y,y_class = process_output(df)\n",
    "    return X,y,y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a34318-a966-4438-80cc-54e8d3c689ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fasta_file = os.path.join('..','repertoire','first_1000.fasta')\n",
    "#sequences = input_file(fasta_file)\n",
    "#chunk_size = 450\n",
    "#X = process_input(sequences, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04bc44a-b5ce-4660-a454-727fd1199cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#annotation_file = os.path.join('..','repertoire','first_1000.tsv')\n",
    "#df = pd.read_csv(annotation_file, sep='\\t', header=0)\n",
    "#y,y_class = process_output(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
